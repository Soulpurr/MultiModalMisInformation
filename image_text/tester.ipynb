{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af71688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as f\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35b1b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTResNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "\n",
    "        super(BERTResNetClassifier, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Image processing (ResNet)\n",
    "        self.image_model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        # Image processing (Fully Connected Layer)\n",
    "        self.fc_image = nn.Linear(in_features=1000, out_features=num_classes, bias=True)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "\n",
    "        # Text processing (using the 768-dimensional BERT arrays)\n",
    "        self.text_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "        # Text processing (Fully Connected Layer)\n",
    "        self.fc_text = nn.Linear(in_features=self.text_model.config.hidden_size, out_features=num_classes, bias=True)\n",
    "\n",
    "        # Fusion and classification\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, image, text_input_ids, text_attention_mask,):\n",
    "        # Image branch\n",
    "        x_img = self.image_model(image)\n",
    "        x_img = self.drop(x_img)\n",
    "        x_img = self.fc_image(x_img)\n",
    "\n",
    "        # Text branch\n",
    "        x_text_last_hidden_states = self.text_model(\n",
    "            input_ids = text_input_ids,\n",
    "            attention_mask = text_attention_mask,\n",
    "            return_dict=False\n",
    "        )\n",
    "        x_text_pooled_output = x_text_last_hidden_states[0][:, 0, :]\n",
    "        x_text = self.drop(x_text_pooled_output)\n",
    "        x_text = self.fc_text(x_text_pooled_output)\n",
    "\n",
    "        # Fusion and max merge\n",
    "        x = torch.max(x_text, x_img)\n",
    "\n",
    "        # Classification\n",
    "        #x = self.softmax(x) #-> already applied in crossentropy loss\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a906bdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abhishek Ramola\\.conda\\envs\\torch\\lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Load model\n",
    "# ========================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define your model class here if not already defined\n",
    "# from your_model_file import MultimodalModel\n",
    "\n",
    "model = BERTResNetClassifier()  # Replace with your model class\n",
    "model.load_state_dict(torch.load(\"./models/modellast.pth\", map_location=device),strict=False)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_bert_embedding(text, max_len=64):\n",
    "    encoding = tokenizer(text, padding='max_length', truncation=True, max_length=max_len, return_tensors=\"pt\")\n",
    "    return encoding['input_ids'].squeeze(0), encoding['attention_mask'].squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fd2b03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def predict_single(model, text, image_path, label_map=None):\n",
    "    model.eval()\n",
    "    \n",
    "    # Preprocess text\n",
    "    input_ids, attention_mask = get_bert_embedding(text)\n",
    "    input_ids = input_ids.unsqueeze(0).to(device)\n",
    "    attention_mask = attention_mask.unsqueeze(0).to(device)\n",
    "\n",
    "    # Preprocess image\n",
    "    mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        output = model(image, input_ids, attention_mask)\n",
    "        pred_class = torch.argmax(output, dim=1).item()\n",
    "    \n",
    "    if label_map:\n",
    "        return label_map[pred_class]  # e.g., label_map = {0: \"True\", 1: \"Fake\", ...}\n",
    "    return pred_class\n",
    "\n",
    "sample_text = \"americas best dance sloth\"\n",
    "sample_image_path = \"./imop.jpg\"  # Update path as needed\n",
    "\n",
    "predicted_label = predict_single(model, sample_text, sample_image_path)\n",
    "print(\"Predicted label:\", predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5254135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
